{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1658933,"sourceType":"datasetVersion","datasetId":982120}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-24T11:56:38.946339Z","iopub.execute_input":"2023-12-24T11:56:38.946824Z","iopub.status.idle":"2023-12-24T11:56:38.961348Z","shell.execute_reply.started":"2023-12-24T11:56:38.946790Z","shell.execute_reply":"2023-12-24T11:56:38.959531Z"},"trusted":true},"execution_count":166,"outputs":[{"name":"stdout","text":"/kaggle/input/time-machine/timemachine.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"1. Load text as strings into memory.\n\n2. Split the strings into tokens (e.g., words or characters).\n\n3. Build a vocabulary dictionary to associate each vocabulary element with a numerical index.\n\n4. Convert the text into sequences of numerical indices","metadata":{}},{"cell_type":"code","source":"import collections \nimport re\nimport random\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom torch.nn import functional as F","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:38.968470Z","iopub.execute_input":"2023-12-24T11:56:38.969019Z","iopub.status.idle":"2023-12-24T11:56:38.976278Z","shell.execute_reply.started":"2023-12-24T11:56:38.968957Z","shell.execute_reply":"2023-12-24T11:56:38.974724Z"},"trusted":true},"execution_count":167,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/time-machine/timemachine.txt',\"r\") as f:\n    txt = f.read()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:38.989473Z","iopub.execute_input":"2023-12-24T11:56:38.989998Z","iopub.status.idle":"2023-12-24T11:56:38.997223Z","shell.execute_reply.started":"2023-12-24T11:56:38.989960Z","shell.execute_reply":"2023-12-24T11:56:38.995724Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"class Vocab:\n    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n        #count token frequencies\n        counter = collections.Counter(tokens)\n        self.token_freqs = sorted(counter.items(), key=lambda x:x[1], reverse=True)\n        \n        #list of unique tokens\n        self.itos = list(sorted(set(['<unk>'] + reserved_tokens + [token for token, freq in self.token_freqs if freq >= min_freq])))\n        self.stoi = {token: idx for idx,token in enumerate(self.itos) }\n        \n    def __len__(self):\n        #length of vocabulary\n        return len(self.itos)\n    \n    def __getitem__(self, tokens):\n        #make tokens into indices\n        if not isinstance(tokens,(list,tuple)):\n            return self.stoi[tokens]\n        return [self.__getitem__(token) for token in tokens]\n    \n    def to_tokens(self,indices):\n        #make indixes into tokens\n        if hasattr(indices,'__len__') and len(indices)>1:\n            return [self.itos[int(index)] for index in indices]\n        return slef.itos[indices]\n    \n    @property\n    def unk(self):\n        return self.token_to_idx['<unk>']","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:39.050017Z","iopub.execute_input":"2023-12-24T11:56:39.050531Z","iopub.status.idle":"2023-12-24T11:56:39.064181Z","shell.execute_reply.started":"2023-12-24T11:56:39.050492Z","shell.execute_reply":"2023-12-24T11:56:39.062754Z"},"trusted":true},"execution_count":169,"outputs":[]},{"cell_type":"code","source":"class text_dataset(Dataset):\n    def __init__(self, num_steps,train= True, train_size=10000, val_size=5000):\n        super().__init__()\n        corpus,self.vocab = self.build(self._load())\n        array = torch.tensor([corpus[i:i+num_steps+1] for i in range(len(corpus)-num_steps)])\n        if train:\n            self.X,self.Y = array[:,:-1][:train_size],array[:,1:][:train_size]\n        else:\n            self.X,self.Y = array[:,:-1][train_size:train_size+val_size],array[:,1:][train_size:train_size+val_size]\n        \n    def _load(self,path= '/kaggle/input/time-machine/timemachine.txt'):\n        with open(path,\"r\") as f:\n            return f.read()\n        \n    def _preprocess(self, raw_text):\n        return re.sub('[^A-Za-z]+',' ',raw_text).lower()\n    \n    def _tokenize(self,text):\n        return list(text)\n    \n    def build(self,raw_text,vocab=None):\n        tokens = self._tokenize(self._preprocess(raw_text))\n        if vocab is None: vocab = Vocab(tokens)\n        corpus = [vocab[token] for token in tokens]\n        return corpus, vocab\n    \n    def __getitem__(self,index):\n        sample = self.X[index],self.Y[index]\n        return sample\n    \n    def __len__(self):\n        return self.X.shape[0]\n","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:39.085574Z","iopub.execute_input":"2023-12-24T11:56:39.086046Z","iopub.status.idle":"2023-12-24T11:56:39.101263Z","shell.execute_reply.started":"2023-12-24T11:56:39.086009Z","shell.execute_reply":"2023-12-24T11:56:39.099746Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"train_data = text_dataset(num_steps=32,train=True)\ntest_data = text_dataset(num_steps=32,train=False)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:39.107338Z","iopub.execute_input":"2023-12-24T11:56:39.107873Z","iopub.status.idle":"2023-12-24T11:56:46.155745Z","shell.execute_reply.started":"2023-12-24T11:56:39.107833Z","shell.execute_reply":"2023-12-24T11:56:46.154335Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"train_data[-1]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.160318Z","iopub.execute_input":"2023-12-24T11:56:46.160852Z","iopub.status.idle":"2023-12-24T11:56:46.172350Z","shell.execute_reply.started":"2023-12-24T11:56:46.160805Z","shell.execute_reply":"2023-12-24T11:56:46.170597Z"},"trusted":true},"execution_count":172,"outputs":[{"execution_count":172,"output_type":"execute_result","data":{"text/plain":"(tensor([ 0,  2, 15,  5,  0, 20, 16, 14,  6,  0, 21, 19,  2, 15, 20, 17,  2, 19,\n          6, 15, 21,  0,  4, 19, 26, 20, 21,  2, 13, 13, 10, 15]),\n tensor([ 2, 15,  5,  0, 20, 16, 14,  6,  0, 21, 19,  2, 15, 20, 17,  2, 19,  6,\n         15, 21,  0,  4, 19, 26, 20, 21,  2, 13, 13, 10, 15,  6]))"},"metadata":{}}]},{"cell_type":"code","source":"test_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.174694Z","iopub.execute_input":"2023-12-24T11:56:46.175202Z","iopub.status.idle":"2023-12-24T11:56:46.186852Z","shell.execute_reply.started":"2023-12-24T11:56:46.175165Z","shell.execute_reply":"2023-12-24T11:56:46.185228Z"},"trusted":true},"execution_count":173,"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"(tensor([ 2, 15,  5,  0, 20, 16, 14,  6,  0, 21, 19,  2, 15, 20, 17,  2, 19,  6,\n         15, 21,  0,  4, 19, 26, 20, 21,  2, 13, 13, 10, 15,  6]),\n tensor([15,  5,  0, 20, 16, 14,  6,  0, 21, 19,  2, 15, 20, 17,  2, 19,  6, 15,\n         21,  0,  4, 19, 26, 20, 21,  2, 13, 13, 10, 15,  6,  0]))"},"metadata":{}}]},{"cell_type":"code","source":"train_loader = DataLoader(dataset=train_data,batch_size=1024,shuffle=True)\ntest_loader = DataLoader(dataset=test_data,batch_size=1024,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.190767Z","iopub.execute_input":"2023-12-24T11:56:46.191223Z","iopub.status.idle":"2023-12-24T11:56:46.199422Z","shell.execute_reply.started":"2023-12-24T11:56:46.191188Z","shell.execute_reply":"2023-12-24T11:56:46.197836Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"samples,labels = next(iter(train_loader))","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.201245Z","iopub.execute_input":"2023-12-24T11:56:46.201663Z","iopub.status.idle":"2023-12-24T11:56:46.225664Z","shell.execute_reply.started":"2023-12-24T11:56:46.201626Z","shell.execute_reply":"2023-12-24T11:56:46.224084Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"samples.shape,labels.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.228351Z","iopub.execute_input":"2023-12-24T11:56:46.228945Z","iopub.status.idle":"2023-12-24T11:56:46.238858Z","shell.execute_reply.started":"2023-12-24T11:56:46.228898Z","shell.execute_reply":"2023-12-24T11:56:46.237222Z"},"trusted":true},"execution_count":176,"outputs":[{"execution_count":176,"output_type":"execute_result","data":{"text/plain":"(torch.Size([1024, 32]), torch.Size([1024, 32]))"},"metadata":{}}]},{"cell_type":"markdown","source":"A language model predicts the probability of a sequence\\\n$ P(x_1, x_2, \\ldots, x_T),$\\\nlanguage model may tell that \"i want to eat grandma\" is less probable than \"i want to eat,grandma\"","metadata":{}},{"cell_type":"markdown","source":"perplexity:\\\n$exp(\\frac{1}{n} \\sum_{t=1}^n -\\log P(x_t \\mid x_{t-1}, \\ldots, x_1))$\\\naverage of probablity of the next token in the actual sequence as predicted by the model","metadata":{}},{"cell_type":"markdown","source":"making tokens of size n:\\\neach epoch discard the first z~unif0,n) tokens\\\nmake it into sample of length n s.t the you start at d and sample subsequences.\n","metadata":{}},{"cell_type":"markdown","source":"9.4-|v|^n b/c storing  larger length subsequence","metadata":{}},{"cell_type":"markdown","source":"$P(x_t \\mid x_{t-1}, \\ldots, x_1) \\approx P(x_t \\mid h_{t-1})$\\\nthe RNN hidden state is like the approximation of history\\\nX_t is a R^nxd implies the t th token (token at timestep t) for minibatches\n$\\mathbf{H}_t = \\phi(\\mathbf{X}_t \\mathbf{W}_{\\textrm{xh}} + \\mathbf{H}_{t-1} \\mathbf{W}_{\\textrm{hh}}  + \\mathbf{b}_\\textrm{h})$\\\n$\\mathbf{O}_t = \\mathbf{H}_t \\mathbf{W}_{\\textrm{hq}} + \\mathbf{b}_\\textrm{q}$","metadata":{}},{"cell_type":"markdown","source":"![image.png](attachment:69df5ba0-506c-48f5-97d9-d0ddbddf8c07.png)","metadata":{},"attachments":{"69df5ba0-506c-48f5-97d9-d0ddbddf8c07.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"nn.Parameters(data=None,requires_grad=True)","metadata":{}},{"cell_type":"code","source":"class RNNscrach(nn.Module):\n    def __init__(self,input_size,hidden_size,sigma=0.01):\n        '''\n        num_input: size of input tokens\n        num_hidden: size if hidden state\n        '''\n        super().__init__()\n        self.sigma = sigma\n        self.hidden_size = hidden_size\n        self.W_xh = nn.Parameter(torch.randn(input_size, hidden_size)*sigma)\n        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size)*sigma)\n        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n        \n    def forward(self,inputs,state=None):\n        '''\n        inputs: shape (num_steps,batch_size,num_inputs)\n        '''\n        if state is None:\n            state = torch.zeros((inputs.shape[1],self.hidden_size),device=inputs.device)\n        else:\n            state = state\n        outputs = []\n        for X in inputs:\n            #iterates time step wise\n            state = torch.tanh(torch.matmul(X, self.W_xh) + \n                              torch.matmul(state,self.W_hh) + self.b_h)\n            outputs.append(state)\n        return outputs,state","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.240765Z","iopub.execute_input":"2023-12-24T11:56:46.241941Z","iopub.status.idle":"2023-12-24T11:56:46.252551Z","shell.execute_reply.started":"2023-12-24T11:56:46.241903Z","shell.execute_reply":"2023-12-24T11:56:46.251295Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"# y = torch.randn(4,4,1)\n# print(y)\n# for x in y:\n#     print(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.254666Z","iopub.execute_input":"2023-12-24T11:56:46.255101Z","iopub.status.idle":"2023-12-24T11:56:46.270200Z","shell.execute_reply.started":"2023-12-24T11:56:46.255068Z","shell.execute_reply":"2023-12-24T11:56:46.268857Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"batch_size, input_size, hidden_size, num_steps = 2, 16, 32, 100\nrnn = RNNscrach(num_inputs,hidden_size)\nx = torch.ones((num_steps, batch_size, input_size))\noutputs,state = rnn(x)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.272511Z","iopub.execute_input":"2023-12-24T11:56:46.274022Z","iopub.status.idle":"2023-12-24T11:56:46.290466Z","shell.execute_reply.started":"2023-12-24T11:56:46.273961Z","shell.execute_reply":"2023-12-24T11:56:46.288920Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"print(len(outputs) == num_steps)\nstate.shape == (batch_size,hidden_size)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.296781Z","iopub.execute_input":"2023-12-24T11:56:46.297484Z","iopub.status.idle":"2023-12-24T11:56:46.307430Z","shell.execute_reply.started":"2023-12-24T11:56:46.297446Z","shell.execute_reply":"2023-12-24T11:56:46.305545Z"},"trusted":true},"execution_count":180,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"},{"execution_count":180,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"class RNNLMscrach(nn.Module):\n    '''language model based on RNN'''\n    def __init__(self, rnn, vocab_size, clip_value=100.0):\n        super().__init__()\n        self.rnn = rnn\n        self.vocab_size = vocab_size\n        self.clip_value = clip_value\n#         self.lr = lr\n        self.W_hq = nn.Parameter(torch.randn(self.rnn.hidden_size,vocab_size)*self.rnn.sigma)\n    #the output size set to be vocab_size\n        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n        \n    def one_hot(self,X):\n        return F.one_hot(X.T, self.vocab_size).type(torch.float32)\n    \n    def output_layer(self,rnn_outputs):\n        outputs = [torch.matmul(H,self.W_hq) + self.b_q for H in rnn_outputs]\n        return torch.stack(outputs, 1)#num_steps,batch_size,vocab_size\n        \n    def forward(self,X,state=None):\n        '''\n        X:batch_size,time_step\n        '''\n        embs = self.one_hot(X)\n        # embs.shape:timesteps,batch_size,embedding_dimension\n        rnn_outputs,_ = self.rnn(embs,state)\n        return self.output_layer(rnn_outputs)\n        \n    def clip_gradient(self):\n        norm = 0\n        for parameter in self.parameters():\n            if parameter.requires_grad:\n                norm += torch.sum(parameter.grad**2)\n            norm = torch.sqrt(norm)\n        if norm > self.clip_value:\n            for param in self.parameters():\n                param.grad*=self.clip_value/norm\n    def generate(self,prefix,num_preds,vocab,device = \"cuda\" if torch.cuda.is_available() else \"cpu\"):\n        state,outputs = None,[vocab[prefix[0]]]#2D array that batch_size,1(index of prefix[0])\n        for i in range(len(prefix) + num_preds - 1):\n            X = torch.tensor([[outputs[-1]]],device=device)\n            embs = self.token_embd(X)\n            rnn_outputs, state = self.rnn(embs,state)\n            if i < len(prefix) - 1:\n                outputs.append(vocab[prefix[i+1]])\n            else:\n                Y = self.output_layer(rnn_outputs)\n                outputs.append(int(Y.argmax(axis=2).reshape(1)))\n        return ''.join([vocab.itos[i] for i in outputs])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:20:09.848662Z","iopub.execute_input":"2023-12-24T12:20:09.850461Z","iopub.status.idle":"2023-12-24T12:20:09.871477Z","shell.execute_reply.started":"2023-12-24T12:20:09.850393Z","shell.execute_reply":"2023-12-24T12:20:09.870324Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"markdown","source":"why one hot encoding?\\\nyou may try to feed the index as inputs but the close indices may not be remotely similar in meaning.\n- after doing one hot encoding it goes from:\\\nbatch_size,num_steps-->num_steps,batch_size-->num_steps,batch_size,|v|","metadata":{}},{"cell_type":"markdown","source":"F.one_hot:\\\n[[0,1],[2,0]]-->\\\n[[[1,0,0],[0,1,0]],[[0,0,1],[1,0,0]]]","metadata":{}},{"cell_type":"markdown","source":"torch.stack(list):\n```\nimport torch\n\ntensor1 = torch.randn(4, 5)  # Shape: 4x5\ntensor2 = torch.randn(4, 5)  # Shape: 4x5\ntensor3 = torch.randn(4, 5)  # Shape: 4x5\n\nlist_of_tensors = [tensor1, tensor2, tensor3]\n\nstacked_tensor = torch.stack(list_of_tensors, 1)\n\nprint(stacked_tensor.shape)  # Output: torch.Size([4, 3, 5])\n```","metadata":{}},{"cell_type":"code","source":"tensor1 = torch.randn(4, 5)  # Shape: 4x5\ntensor2 = torch.randn(4, 5)  # Shape: 4x5\ntensor3 = torch.randn(4, 5)  # Shape: 4x5\nprint(tensor1,tensor2,tensor3)\nlist_of_tensors = [tensor1, tensor2, tensor3]\n\nstacked_tensor = torch.stack(list_of_tensors, 1)\n\nprint(stacked_tensor)  ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.333099Z","iopub.execute_input":"2023-12-24T11:56:46.334068Z","iopub.status.idle":"2023-12-24T11:56:46.351173Z","shell.execute_reply.started":"2023-12-24T11:56:46.334012Z","shell.execute_reply":"2023-12-24T11:56:46.349339Z"},"trusted":true},"execution_count":182,"outputs":[{"name":"stdout","text":"tensor([[-0.7861, -1.0385,  0.2893, -0.3616, -1.7405],\n        [-0.1998,  0.1163,  1.0202,  0.2310, -0.7437],\n        [-1.8071, -0.3671, -0.2501, -0.8537,  0.5127],\n        [ 0.1397,  1.4585, -2.0581, -0.8796,  1.0938]]) tensor([[ 1.2852e+00,  1.5241e-03, -2.6318e-01,  1.4923e+00,  1.8825e+00],\n        [-3.0074e-01, -1.1727e+00,  2.4738e+00, -8.5257e-01, -1.3372e-01],\n        [ 2.3629e+00, -6.3944e-01,  3.5097e-01,  9.6859e-01, -2.9261e-02],\n        [ 5.7588e-01, -4.7455e-01, -2.9137e-01,  1.5688e+00, -3.9584e-02]]) tensor([[-0.1936, -0.2966,  0.9423,  0.1863,  0.6916],\n        [-0.7502, -0.2274,  0.1436,  0.1031,  0.0346],\n        [-1.8975,  0.5387, -0.9364, -0.7925,  0.1992],\n        [ 0.9217,  1.5563,  0.3821, -0.0488, -0.5879]])\ntensor([[[-7.8609e-01, -1.0385e+00,  2.8934e-01, -3.6163e-01, -1.7405e+00],\n         [ 1.2852e+00,  1.5241e-03, -2.6318e-01,  1.4923e+00,  1.8825e+00],\n         [-1.9357e-01, -2.9658e-01,  9.4228e-01,  1.8626e-01,  6.9162e-01]],\n\n        [[-1.9980e-01,  1.1626e-01,  1.0202e+00,  2.3095e-01, -7.4365e-01],\n         [-3.0074e-01, -1.1727e+00,  2.4738e+00, -8.5257e-01, -1.3372e-01],\n         [-7.5025e-01, -2.2743e-01,  1.4362e-01,  1.0310e-01,  3.4636e-02]],\n\n        [[-1.8071e+00, -3.6711e-01, -2.5014e-01, -8.5369e-01,  5.1265e-01],\n         [ 2.3629e+00, -6.3944e-01,  3.5097e-01,  9.6859e-01, -2.9261e-02],\n         [-1.8975e+00,  5.3866e-01, -9.3639e-01, -7.9247e-01,  1.9919e-01]],\n\n        [[ 1.3973e-01,  1.4585e+00, -2.0581e+00, -8.7965e-01,  1.0938e+00],\n         [ 5.7588e-01, -4.7455e-01, -2.9137e-01,  1.5688e+00, -3.9584e-02],\n         [ 9.2169e-01,  1.5563e+00,  3.8213e-01, -4.8761e-02, -5.8793e-01]]])\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = RNNLMscrach(rnn, input_size)#this decodes to a size same as the input\n# outputs = model(torch.ones((batch_size,num_steps),dtype=torch.int64))\n# outputs.shape","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:56:46.353879Z","iopub.execute_input":"2023-12-24T11:56:46.356264Z","iopub.status.idle":"2023-12-24T11:56:46.362642Z","shell.execute_reply.started":"2023-12-24T11:56:46.356198Z","shell.execute_reply":"2023-12-24T11:56:46.360940Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"rnn = RNNscrach(input_size=len(train_data.vocab),hidden_size=32)\nmodel = RNNLMscrach(rnn,vocab_size=len(train_data.vocab) )#this decodes to a size same as the input","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:20:12.593305Z","iopub.execute_input":"2023-12-24T12:20:12.593740Z","iopub.status.idle":"2023-12-24T12:20:12.601002Z","shell.execute_reply.started":"2023-12-24T12:20:12.593694Z","shell.execute_reply":"2023-12-24T12:20:12.599152Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"for i in model.parameters():\n    print(i.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:19:13.661634Z","iopub.execute_input":"2023-12-24T12:19:13.662119Z","iopub.status.idle":"2023-12-24T12:19:13.670127Z","shell.execute_reply.started":"2023-12-24T12:19:13.662059Z","shell.execute_reply":"2023-12-24T12:19:13.668500Z"},"trusted":true},"execution_count":235,"outputs":[{"name":"stdout","text":"torch.Size([32, 28])\ntorch.Size([28])\ntorch.Size([28, 32])\ntorch.Size([32, 32])\ntorch.Size([32])\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_data.vocab)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:19:14.693782Z","iopub.execute_input":"2023-12-24T12:19:14.694195Z","iopub.status.idle":"2023-12-24T12:19:14.702825Z","shell.execute_reply.started":"2023-12-24T12:19:14.694164Z","shell.execute_reply":"2023-12-24T12:19:14.700969Z"},"trusted":true},"execution_count":236,"outputs":[{"execution_count":236,"output_type":"execute_result","data":{"text/plain":"28"},"metadata":{}}]},{"cell_type":"code","source":"lr = 1\nnum_epochs = 100\noptimizer = torch.optim.AdamW(model.parameters(),lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:19:15.157511Z","iopub.execute_input":"2023-12-24T12:19:15.158136Z","iopub.status.idle":"2023-12-24T12:19:15.169338Z","shell.execute_reply.started":"2023-12-24T12:19:15.158097Z","shell.execute_reply":"2023-12-24T12:19:15.167328Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):    \n    for i,(sample,targets) in enumerate(train_loader):\n        out = model(sample)\n        #out.shape:num_steps,batch_size,channel/vocab\n        num_steps,batch_size,vocab_size = out.shape\n        out = out.view(num_steps*batch_size,-1)\n        targets = targets.view(num_steps*batch_size,)\n#         if i==0:\n#             print(out.shape,targets.shape)\n#             break\n        loss = F.cross_entropy(out,targets)\n        optimizer.zero_grad()\n        loss.backward()\n#         model.clip_gradient()\n        optimizer.step() ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:19:17.199715Z","iopub.execute_input":"2023-12-24T12:19:17.200171Z","iopub.status.idle":"2023-12-24T12:19:34.890224Z","shell.execute_reply.started":"2023-12-24T12:19:17.200139Z","shell.execute_reply":"2023-12-24T12:19:34.888145Z"},"trusted":true},"execution_count":238,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[238], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m         loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(out,targets)\n\u001b[1;32m     12\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         model.clip_gradient()\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mstep() \n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"loss.item()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:19:38.181284Z","iopub.execute_input":"2023-12-24T12:19:38.182660Z","iopub.status.idle":"2023-12-24T12:19:38.190368Z","shell.execute_reply.started":"2023-12-24T12:19:38.182606Z","shell.execute_reply":"2023-12-24T12:19:38.189160Z"},"trusted":true},"execution_count":239,"outputs":[{"execution_count":239,"output_type":"execute_result","data":{"text/plain":"2.7118725776672363"},"metadata":{}}]},{"cell_type":"code","source":"model.generate('father is using mobile', 20, train_data.vocab)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:20:16.254833Z","iopub.execute_input":"2023-12-24T12:20:16.255250Z","iopub.status.idle":"2023-12-24T12:20:16.283507Z","shell.execute_reply.started":"2023-12-24T12:20:16.255218Z","shell.execute_reply":"2023-12-24T12:20:16.281840Z"},"trusted":true},"execution_count":243,"outputs":[{"execution_count":243,"output_type":"execute_result","data":{"text/plain":"'father is using mobile                    '"},"metadata":{}}]},{"cell_type":"code","source":"a=torch.tensor([[1,0,0],[0,1,0]])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:57:37.667616Z","iopub.execute_input":"2023-12-24T11:57:37.668624Z","iopub.status.idle":"2023-12-24T11:57:37.675042Z","shell.execute_reply.started":"2023-12-24T11:57:37.668582Z","shell.execute_reply":"2023-12-24T11:57:37.673511Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"torch.max(a,dim=1)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:57:37.677361Z","iopub.execute_input":"2023-12-24T11:57:37.677956Z","iopub.status.idle":"2023-12-24T11:57:37.692238Z","shell.execute_reply.started":"2023-12-24T11:57:37.677903Z","shell.execute_reply":"2023-12-24T11:57:37.690682Z"},"trusted":true},"execution_count":192,"outputs":[{"execution_count":192,"output_type":"execute_result","data":{"text/plain":"torch.return_types.max(\nvalues=tensor([1, 1]),\nindices=tensor([0, 1]))"},"metadata":{}}]},{"cell_type":"code","source":"a=[[1]]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:57:37.694173Z","iopub.execute_input":"2023-12-24T11:57:37.697187Z","iopub.status.idle":"2023-12-24T11:57:37.703355Z","shell.execute_reply.started":"2023-12-24T11:57:37.697118Z","shell.execute_reply":"2023-12-24T11:57:37.702329Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"a[-1]","metadata":{"execution":{"iopub.status.busy":"2023-12-24T11:57:37.705161Z","iopub.execute_input":"2023-12-24T11:57:37.706062Z","iopub.status.idle":"2023-12-24T11:57:37.718637Z","shell.execute_reply.started":"2023-12-24T11:57:37.706010Z","shell.execute_reply":"2023-12-24T11:57:37.717150Z"},"trusted":true},"execution_count":194,"outputs":[{"execution_count":194,"output_type":"execute_result","data":{"text/plain":"[1]"},"metadata":{}}]},{"cell_type":"markdown","source":"warmup:\\\nwhen beginning prediction start by passing the 'prefix' one by one into the rnn and start predicting from the last prefix token output till the required length.\\\n","metadata":{}},{"cell_type":"markdown","source":"lipschitz conts:\\\n$|f(\\mathbf{x}) - f(\\mathbf{y})| \\leq L \\|\\mathbf{x} - \\mathbf{y}\\|.\n$\\\ngradient clipping:\\\n$\\mathbf{g} \\leftarrow \\min\\left(1, \\frac{\\theta}{\\|\\mathbf{g}\\|}\\right) \\mathbf{g}$","metadata":{}},{"cell_type":"markdown","source":"exercise:\\\n9\n","metadata":{}},{"cell_type":"code","source":"class RNNLMembd(nn.Module):\n    '''language model based on RNN'''\n    def __init__(self, rnn, vocab_size, clip_value=100.0):\n        super().__init__()\n        self.rnn = rnn\n        self.vocab_size = vocab_size\n        self.clip_value = clip_value\n        self.token_embd = nn.Embedding(vocab_size,rnn.hidden_size)\n#         self.lr = lr\n        self.W_hq = nn.Parameter(torch.randn(self.rnn.hidden_size,vocab_size)*self.rnn.sigma)\n    #the output size set to be vocab_size\n        self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n        \n#     def one_hot(self,X):\n#         return F.one_hot(X.T, self.vocab_size).type(torch.float32)\n    \n    def output_layer(self,rnn_outputs):\n        outputs = [torch.matmul(H,self.W_hq) + self.b_q for H in rnn_outputs]\n        return torch.stack(outputs, 1)#num_steps,batch_size,vocab_size\n        \n    def forward(self,X,state=None):\n        '''\n        X:batch_size,time_step\n        '''\n        embs = self.token_embd(X.T)\n        # embs.shape:timesteps,batch_size,embedding_dimension\n        rnn_outputs,_ = self.rnn(embs,state)\n        return self.output_layer(rnn_outputs)\n        \n    def clip_gradient(self):\n        norm = 0\n        for parameter in self.parameters():\n            if parameter.requires_grad:\n                norm += torch.sum(parameter.grad**2)\n            norm = torch.sqrt(norm)\n        if norm > self.clip_value:\n            for param in self.parameters():\n                param.grad*=self.clip_value/norm\n    def generate(self,prefix,num_preds,vocab,device = \"cuda\" if torch.cuda.is_available() else \"cpu\"):\n        state,outputs = None,[vocab[prefix[0]]]#2D array that batch_size,1(index of prefix[0])\n        for i in range(len(prefix) + num_preds - 1):\n            X = torch.tensor([[outputs[-1]]],device=device)\n            embs = self.token_embd(X)\n            rnn_outputs, state = self.rnn(embs,state)\n            if i < len(prefix) - 1:\n                outputs.append(vocab[prefix[i+1]])\n            else:\n                Y = self.output_layer(rnn_outputs)\n                probs = F.softmax(Y,dim=2)\n                outputs.append(int(torch.multinomial(probs[0,0,:],num_samples=1).reshape(1)))\n        return ''.join([vocab.itos[i] for i in outputs])","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:47.609683Z","iopub.execute_input":"2023-12-24T12:26:47.610143Z","iopub.status.idle":"2023-12-24T12:26:47.630816Z","shell.execute_reply.started":"2023-12-24T12:26:47.610110Z","shell.execute_reply":"2023-12-24T12:26:47.629560Z"},"trusted":true},"execution_count":264,"outputs":[]},{"cell_type":"code","source":"class RNNembd(nn.Module):\n    def __init__(self,input_size,hidden_size,sigma=0.01):\n        '''\n        num_input: size of input tokens\n        num_hidden: size if hidden state\n        '''\n        super().__init__()\n        self.sigma = sigma\n        self.hidden_size = hidden_size\n#         self.W_xh = nn.Parameter(torch.randn(input_size, hidden_size)*sigma)\n        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size)*sigma)\n        self.b_h = nn.Parameter(torch.zeros(hidden_size))\n        \n    def forward(self,inputs,state=None):\n        '''\n        inputs: shape (num_steps,batch_size,num_inputs)\n        '''\n        if state is None:\n            state = torch.zeros((inputs.shape[1],self.hidden_size),device=inputs.device)\n        else:\n            state = state\n        outputs = []\n        for X in inputs:\n            #iterates time step wise\n            state = torch.tanh(X + \n                              torch.matmul(state,self.W_hh) + self.b_h)\n            outputs.append(state)\n        return outputs,state","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:47.804974Z","iopub.execute_input":"2023-12-24T12:26:47.805468Z","iopub.status.idle":"2023-12-24T12:26:47.816837Z","shell.execute_reply.started":"2023-12-24T12:26:47.805430Z","shell.execute_reply":"2023-12-24T12:26:47.815672Z"},"trusted":true},"execution_count":265,"outputs":[]},{"cell_type":"code","source":"rnn = RNNembd(input_size=len(train_data.vocab),hidden_size=32)\nmodel = RNNLMembd(rnn,vocab_size=len(train_data.vocab) )#this decodes to a size same as the input","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:47.993043Z","iopub.execute_input":"2023-12-24T12:26:47.993483Z","iopub.status.idle":"2023-12-24T12:26:48.000586Z","shell.execute_reply.started":"2023-12-24T12:26:47.993448Z","shell.execute_reply":"2023-12-24T12:26:47.999509Z"},"trusted":true},"execution_count":266,"outputs":[]},{"cell_type":"code","source":"for i in model.parameters():\n    print(i.shape)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:48.174801Z","iopub.execute_input":"2023-12-24T12:26:48.175193Z","iopub.status.idle":"2023-12-24T12:26:48.182100Z","shell.execute_reply.started":"2023-12-24T12:26:48.175162Z","shell.execute_reply":"2023-12-24T12:26:48.180839Z"},"trusted":true},"execution_count":267,"outputs":[{"name":"stdout","text":"torch.Size([32, 28])\ntorch.Size([28])\ntorch.Size([32, 32])\ntorch.Size([32])\ntorch.Size([28, 32])\n","output_type":"stream"}]},{"cell_type":"code","source":"len(train_data.vocab)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:49.154397Z","iopub.execute_input":"2023-12-24T12:26:49.154938Z","iopub.status.idle":"2023-12-24T12:26:49.164676Z","shell.execute_reply.started":"2023-12-24T12:26:49.154892Z","shell.execute_reply":"2023-12-24T12:26:49.162839Z"},"trusted":true},"execution_count":268,"outputs":[{"execution_count":268,"output_type":"execute_result","data":{"text/plain":"28"},"metadata":{}}]},{"cell_type":"code","source":"lr = 1e-2\nnum_epochs = 100\noptimizer = torch.optim.AdamW(model.parameters(),lr=lr)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:49.451067Z","iopub.execute_input":"2023-12-24T12:26:49.451548Z","iopub.status.idle":"2023-12-24T12:26:49.459281Z","shell.execute_reply.started":"2023-12-24T12:26:49.451508Z","shell.execute_reply":"2023-12-24T12:26:49.457367Z"},"trusted":true},"execution_count":269,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):    \n    for i,(sample,targets) in enumerate(train_loader):\n        out = model(sample)\n        #out.shape:num_steps,batch_size,channel/vocab\n        num_steps,batch_size,vocab_size = out.shape\n        out = out.view(num_steps*batch_size,-1)\n        targets = targets.view(num_steps*batch_size,)\n#         if i==0:\n#             print(out.shape,targets.shape)\n#             break\n        loss = F.cross_entropy(out,targets)\n        optimizer.zero_grad()\n        loss.backward()\n        model.clip_gradient()\n        optimizer.step() ","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:26:49.611034Z","iopub.execute_input":"2023-12-24T12:26:49.611460Z","iopub.status.idle":"2023-12-24T12:27:40.077448Z","shell.execute_reply.started":"2023-12-24T12:26:49.611429Z","shell.execute_reply":"2023-12-24T12:27:40.076007Z"},"trusted":true},"execution_count":270,"outputs":[]},{"cell_type":"code","source":"loss.item()","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:27:40.079751Z","iopub.execute_input":"2023-12-24T12:27:40.080190Z","iopub.status.idle":"2023-12-24T12:27:40.089448Z","shell.execute_reply.started":"2023-12-24T12:27:40.080156Z","shell.execute_reply":"2023-12-24T12:27:40.088279Z"},"trusted":true},"execution_count":271,"outputs":[{"execution_count":271,"output_type":"execute_result","data":{"text/plain":"1.448016881942749"},"metadata":{}}]},{"cell_type":"code","source":"model.generate('father is using mobile', 20, train_data.vocab)","metadata":{"execution":{"iopub.status.busy":"2023-12-24T12:27:40.091994Z","iopub.execute_input":"2023-12-24T12:27:40.092784Z","iopub.status.idle":"2023-12-24T12:27:40.120908Z","shell.execute_reply.started":"2023-12-24T12:27:40.092742Z","shell.execute_reply":"2023-12-24T12:27:40.119424Z"},"trusted":true},"execution_count":272,"outputs":[{"execution_count":272,"output_type":"execute_result","data":{"text/plain":"'father is using mobiled the weacen theng t'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}